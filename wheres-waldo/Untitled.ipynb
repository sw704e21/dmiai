{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8122ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "import sys as sys\n",
    "sys.path.append(r'C:\\Users\\lasse\\Documents\\GitHub\\DM-i-AI\\wheres-waldo\\keras-retinanet')\n",
    "from utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from utils.visualization import draw_box, draw_caption\n",
    "from utils.colors import label_color\n",
    "from utils.gpu import setup_gpu\n",
    "from keras_retinanet.models import load_model\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import image_slicer\n",
    "import PIL\n",
    "\n",
    "class Model():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.image = 0\n",
    "        self.scale = 0\n",
    "        self.draw = []\n",
    "        self.labels_to_name = {}\n",
    "        self.mapping = [[0, 0], [300, 0], [600, 0], [900, 0], [1200, 0], [0, 300],  [300, 300],  [600, 300],  [900, 300],  [1200, 300], [0, 600],  [300, 600],  [600, 600],  [900, 600],  [1200, 600], [0, 900],  [300, 900],  [600, 900],  [900, 900],  [1200, 900], [0, 1200], [300, 1200], [600, 1200], [900, 1200], [1200, 1200]]\n",
    "    \n",
    "    def _postprocess_data(self, samples):\n",
    "        count = 0\n",
    "        bstcount = 0\n",
    "        bestpred = 0\n",
    "        \n",
    "        boxes = samples[0]\n",
    "        preds = samples[1]\n",
    "        \n",
    "        print(len(boxes))\n",
    "        print(len(preds))\n",
    "        \n",
    "        print(boxes[0].shape)\n",
    "        print(preds[0].shape)\n",
    "        \n",
    "        print(boxes)\n",
    "        print(preds)\n",
    "        \n",
    "        print(\"##########\")\n",
    "        \n",
    "        for sample in samples[1]:\n",
    "            if sample[1] > bestpred:\n",
    "                boxes = samples[0][count][0]\n",
    "                bstcount = count\n",
    "            count = count + 1\n",
    "            \n",
    "        print(boxes)    \n",
    "        \n",
    "        x_center = boxes[1] + (boxes[3] - boxes[1]) / 2\n",
    "        y_center = boxes[0] + (boxes[2] - boxes[0]) / 2\n",
    "\n",
    "        print(x_center)\n",
    "        print(y_center)\n",
    "        \n",
    "        p = self.mapping[10]\n",
    "        print(p)\n",
    "        point = p[0] + x_center, p[1] + y_center\n",
    "        return point\n",
    "\n",
    "    def forward(self, sample):\n",
    "        sample = self._preprocess_data(sample)\n",
    "        result = self.predict(sample)\n",
    "        return result\n",
    "\n",
    "    def predict(self, data):\n",
    "        labels_to_names = {1: 'Waldo'}\n",
    "        for image in data:\n",
    "            self.draw = image.copy()\n",
    "            self.draw = cv2.cvtColor(self.draw, cv2.COLOR_BGR2RGB)\n",
    "            image = preprocess_image(image)\n",
    "            image, scale = resize_image(image)\n",
    "            boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "            #print(\"processing time: \", time.time() - start)\n",
    "            # correct for image scale\n",
    "            boxes /= scale\n",
    "            fin = 0\n",
    "            count = 0\n",
    "\n",
    "            for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "                # scores are sorted so we can break\n",
    "                count = count + 1\n",
    "                if score < 0.5:\n",
    "                    break\n",
    "                color = label_color(label)\n",
    "                b = box.astype(int)\n",
    "                sc = score\n",
    "                box = draw_box(self.draw, b, color=color)\n",
    "\n",
    "                caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "                draw_caption(self.draw, b, caption)\n",
    "                \n",
    "        y_center = b[1] + (b[3] - b[1]) / 2\n",
    "        x_center = b[0] + (b[2] - b[0]) / 2\n",
    "        \n",
    "        p = self.mapping[10]\n",
    "        point = p[0] + x_center, p[1] + y_center\n",
    "        \n",
    "        return point\n",
    "    \n",
    "    def _preprocess_data(self, data):\n",
    "        data = PIL.Image.open(data).convert('RGB')\n",
    "        data = np.asarray(data)\n",
    "        images = []\n",
    "        r = 300\n",
    "        #print(data)\n",
    "        for i in range(5):\n",
    "            row = data[r * i: r * (i + 1), :, :]\n",
    "            for j in range(5):\n",
    "                images.append(row[:, r * j: r * (j + 1), :])\n",
    "        result = []\n",
    "        for image in images:\n",
    "            labels_to_names = {1: 'Waldo'}\n",
    "            image = preprocess_image(image)\n",
    "            images, scales = resize_image(image)\n",
    "            result.append(image)   \n",
    "        result = np.array(result)\n",
    "        return result\n",
    "\n",
    "    def save_model(self, save_path):\n",
    "        model = load_model(r'\\WaldoModel\\my_model.h5', backbone_name = 'resnet50')\n",
    "\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8fcc6aad-a6e0-42a4-805c-ba77cae1772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras_retinanet.models import load_model\n",
    "\n",
    "\n",
    "# load retinanet model\n",
    "#model = load_model('./WaldoModel/themodel.h5', backbone_name = 'resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1dfb43cd-57c1-460f-b793-41790fcfd743",
   "metadata": {},
   "outputs": [],
   "source": [
    "themodel = Model()\n",
    "\n",
    "images = themodel._preprocess_data(r\"./test/waldo.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ebc710f4-1ac6-42ec-acca-7b4b921deb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = model.predict_on_batch(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8af63990-a75a-42f7-8f09-746dd3618278",
   "metadata": {},
   "outputs": [],
   "source": [
    "coor = themodel.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1bb5a14b-d451-42be-a886-33d23555c9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126.5, 837.5)\n"
     ]
    }
   ],
   "source": [
    "print(coor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "ebf87edf-c15b-4fa1-9031-dd11cbfa5588",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\lasse\\\\Desktop\\\\WheresWaldo\\\\waldo.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-518-df342801aa4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_slicer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"C:\\Users\\lasse\\Desktop\\WheresWaldo\\waldo.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/image_slicer/main.py\u001b[0m in \u001b[0;36mslice\u001b[0;34m(filename, number_tiles, col, row, save, DecompressionBombWarning)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_IMAGE_PIXELS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0mim_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2878\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2879\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\lasse\\\\Desktop\\\\WheresWaldo\\\\waldo.jpg'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712830e-dd88-445a-9520-99357ba81dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
